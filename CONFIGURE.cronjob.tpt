%[** Template for SWT file 'swtcronjob2' expanded by 'configure' **]%
%[**  **]%
%[** THVV 08/11/06 **]%
%[** THVV 03/06/21 use REPORTDIR **]%
%[** THVV 03/29/21 **]%
%[** ================================================================ **]%
#!/bin/sh
# Shell script run by cron every day to create website usage report using Super Webtrax.
# -- do dns processing in logextractor2
# -- Saves the logs as a date file instead of deleting them.
# -- Rename old reports as date files.
# script generated by configure on %[timestamp]%
#
################################################################
# .. where raw logs are found
export RAWLOGS=%[RAWLOGS]%
# .. where bad logs are put
export BADLOGS=%[BADLOGS]%
# .. where finished logs are put
export DONELOGS=%[DONELOGS]%
# .. where programs live
export BIN=$HOME/bin
# .. where data is kept
export DATADIR=%[DATADIR]%
# .. where the output goes
export REPORTDIR=%[REPORTDIR]%
# .. prefix for the log files
export LOGFILEPREFIX=%[LOGFILEPREFIX]%
##export LOGFILEPREFIX=comb ## not doing this, different template
## .. log file combiner config file
##export COMBCONF=$DATADIR/combinelogs.conf
# ..the geoip arg and path
%[*if,eq,GEOIPDATADIR,="",*set,&GEOIPARG,=""]%
%[*if,ne,GEOIPDATADIR,="",*set,&GEOIPARG,=-geoipcity %[GEOIPDATADIR]%/GeoLiteCity.dat]%
# .. patterns for moving logfiles .. may contain logfiles we do not process
export LOGFILESTAR="$LOGFILEPREFIX.*"
%[*warn,*** edit swtcronjob2.sh LOGFILESTAR=]%
# .. make sure PERL5LIB is set
if [ -z "$PERL5LIB" ] ; then
    echo "PERL5LIB is null, setting to $BIN"
    export PERL5LIB=$BIN
fi
################################################################
# .. could generate postamble.txt here
################################################################
#
#
cd $RAWLOGS
export GEOIPARG=%[GEOIPARG]%
#
if [ "$LOGFILEPREFIX" = "comb" ] ; then # not doing this, selected at configure
    ls -l
    # combine and merge the logs: $BIN/combinelogs reads a config file with the specific logs and suffixes, calls $BIN/logmerge
    # link $RAWLOGS/readapacheline.pm must exist
    echo "Combining separated logs..."
    cat $COMBCONF
    nice $BIN/combinelogs $COMBCONF | sh
    mv $LOGFILESTAR $DONELOGS
fi
# do all the logs (in random order)
for i in $LOGFILEPREFIX.*
do
    if test "$LOGFILEPREFIX.*" = $i
    then # no logs
	# if the wildcard doesn't match anything, it runs once with "$LOGFILEPREFIX.*"
	echo "logs missing"
    else # found logs
	export systype=`uname -s`
	case "$systype" in
	    "Darwin")
		export yesterday=`date -v-1d "+%F"`;;
	    "FreeBSD")
		export yesterday=`date -v-1d "+%F"`;;
	    "Linux")
		export yesterday=`date --date="1 days ago" "+%F"`;;
	    *) # SunOS, HP-UX, OSF1, IRIX, IRIX64, AIX
		export yesterday="yesterday";;
	esac
	# save the old reports -- clean these out every so often
	cd $REPORTDIR
	test -f swtreport.html && mv swtreport.html swtreport.$yesterday.html
	test -f important.html && mv important.html important.$yesterday.html
	test -f swtdash.csv && mv swtdash.csv swtdash.$yesterday.csv
	# move the logfile into logproc
	cd $RAWLOGS
	mv $i $DATADIR
	# back stuff up in case of problems
	cd $DATADIR
	cp cumdump.sql.gz cumdump.sql.0.gz
	# process with geoip and generate templog
	# .. use -dns dnscache if the log has not had its reverse lookups done already
	# .. see 'configure' for info on Perl modules, MaxMind libraries, and MaxMind free city database and licenxe
	echo "Extracting templog from $i"
	nice $BIN/logextractor2 -day all $GEOIPARG -dns dnscache $i > templog
	errorwas=$?
	# jobs killed by reaper will get nonzero retcode
	if [ $errorwas != 0 ] ; then 
	    # ----------- logextractor2 failed -------------
	    # try once more, sometimes the reaper wacks me right away
	    echo "*** trying logextractor2 one more time after error $errorwas"
	    sleep 60
	    nice $BIN/logextractor2 -day all $GEOIPARG -dns dnscache $i > templog
	    errorwas=$?
	    if [ $errorwas != 0 ] ; then 
		# try once more, maybe it was geoip
		echo "*** trying logextractor2 one more time without geoip after error $errorwas"
		sleep 60
		#nice $BIN/logextractor2 -day all $i > templog
		nice $BIN/logextractor2 -day all -dns dnscache $i > templog
		errorwas=$?
	    fi
	fi
	if [ $errorwas = 0 ] ; then 
	    # ----------- logextractor2 ok -------------
	    # generate the report -- each step is niced
	    ./swt templog
	    errorwas=$?
	    if [ $errorwas != 0 ] ; then 
		echo "*** swt failed, error $errorwas"
		# database may be down
		echo "*** moving $i to badlogs and bailing out"
		echo "*** recovery will depend on how far swt got"
		mv $i $BADLOGS/
		cd $REPORTDIR
		mv swtreport.$yesterday.html swtreport.html
		mv important.$yesterday.html important.html
		mv swtdash.$yesterday.csv swtdash.csv
		exit 1
	    fi
	    # swt completed, did it write its output?
	    if test -r swtreport.html
	    then
		# ----------- swt report exists -------------
		rm templog
		# done with input file
		if test -r $LOGFILEPREFIX.*.gz
		then # gzip
		    mv $i httpd_access.$yesterday.gz
		else # not gzip
		    mv $i httpd_access.$yesterday
		    rm -f httpd_access.$yesterday.gz
		    gzip httpd_access.$yesterday
		fi # not gzip
		mv httpd_access.$yesterday.gz $DONELOGS
		# move the report to the web directory
		chmod 644 swtreport.html important.html info.html configdisplay.html swtdash.csv
		mv info.html configdisplay.html important.html swtreport.html swtdash.csv $REPORTDIR
		# can't have a ton of these logs piling up
		cd $DONELOGS
		rm $LOGFILESTAR
		cd
	    else
		# ----------- report failed, try to recover by splitting templog -------------
		# .. may not get in here if the errcode check above gets an error for the reaper
		# .. if reaped during data load, assume no need to restore the dump ..
		echo "*** swt failed on $i"
		if test -f templog
		then # templog created
		    echo "*** attempting recovery"
		    wc -l templog
		    # divide the log file into 10000 record chunks templog.1, templog.2, etc
		    nice $BIN/divfilen templog
		    if test -f templog.2
		    then # divfilen worked, do all the parts
			for j in templog.*
			do
			    echo ./swt $j
			    ./swt $j
			    if test -r swtreport.html
			    then # templog.X OK
				rm $j
				# move the report to the web directory as swtreport.html and as templog.N.html
				# clean these out later
				chmod 644 swtreport.html info.html configdisplay.html important.html swtdash.csv
				cp swtreport.html $REPORTDIR/$j.html
				mv info.html configdisplay.html important.html swtreport.html swtdash.csv $REPORTDIR
				# one done
			    else  # templog.X failed
				echo "*** $i $j failed, put $j in badlogs"
				mv $j $BADLOGS/$i.$j
			    fi # templog.X failed
			done
			# did all the parts, clean up
			echo "*** recovery done"
			mv $i httpd_access.$yesterday.gz
			mv httpd_access.$yesterday.gz $DONELOGS
			rm templog
		    else # divfile failed
			echo "*** divfile failed, put $i in badlogs, bailing out"
			mv $i $BADLOGS
		    fi # divfile failed
		else # templog not created
		    echo "*** templog was not created, put $i in badlogs, bailing out"
		    mv $i $BADLOGS
		fi # templog not created
	    fi # report failed regular way
	else
	    echo "logextractor2 failed, put $i in badlogs, bailing out, error:" $errorwas
	    mv $i $BADLOGS
	    # restore the old reports
	    cd $REPORTDIR
	    mv swtreport.$yesterday.html swtreport.html
	    mv important.$yesterday.html important.html
	    mv swtdash.$yesterday.csv swtdash.csv
	fi
    fi # found logs
done
# Insert additional local reporting tasks here
# end
